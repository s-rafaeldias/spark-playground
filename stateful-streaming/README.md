# Stateful processing in Pyspark

## Running the example
```bash
pip install -r requirements.txt
python main.py
```

## References
- https://www.waitingforcode.com/apache-spark-structured-streaming/arbitrary-stateful-processing-pyspark-applyinpandaswithstate/read
- https://spark.apache.org/docs/latest/api//python/reference/pyspark.sql/api/pyspark.sql.GroupedData.applyInPandasWithState.html?highlight=applyinpandaswithstate#pyspark.sql.GroupedData.applyInPandasWithState
- https://github.com/bartosz25/spark-playground/tree/master/pyspark-arbitrary-stateful-processing
